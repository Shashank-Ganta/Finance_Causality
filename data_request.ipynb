{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import numpy as np\n",
    "import csv \n",
    "quandl.ApiConfig.api_key = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_data = quandl.Dataset('WIKI/AAPL').data(params={ 'start_date':'2010-01-01', 'end_date':'2017-01-01', 'collapse':'weekly', 'transformation':'rdiff', 'rows':1000 })\n",
    "test_dataset_data = quandl.Dataset('WIKI/AAPL').data(params={ 'start_date':'2017-01-01', 'end_date':'2018-01-01', 'collapse':'weekly', 'transformation':'rdiff', 'rows':1000 })\n",
    "total_dataset_data = quandl.Dataset('WIKI/AAPL').data(params={ 'start_date':'2010-01-01', 'end_date':'2018-01-01', 'collapse':'weekly', 'transformation':'rdiff', 'rows':1000 })\n",
    "\n",
    "\n",
    "train_np = train_dataset_data.to_numpy()\n",
    "test_np = test_dataset_data.to_numpy()\n",
    "total_np = total_dataset_data.to_numpy()\n",
    "\n",
    "\n",
    "train_data = [[\"date\",'adj_open','adj_high','adj_low','adj_close','adj_volume']]\n",
    "test_data = [[\"date\",'adj_open','adj_high','adj_low','adj_close','adj_volume']]\n",
    "total_data = [[\"date\",'adj_open','adj_high','adj_low','adj_close','adj_volume']]\n",
    "\n",
    "for date in train_np:\n",
    "    train_data.append([str(date[0])[:10],date[8],date[9],date[10],date[11],date[12]])\n",
    "for date in test_np:\n",
    "    test_data.append([str(date[0])[:10],date[8],date[9],date[10],date[11],date[12]])\n",
    "for date in total_np:\n",
    "    total_data.append([str(date[0])[:10],date[8],date[9],date[10],date[11],date[12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\icode\\\\Downloads\\\\APPL_train.csv\", 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile,lineterminator = '\\n') \n",
    "    csvwriter.writerows(train_data)\n",
    "with open(\"C:\\\\Users\\\\icode\\\\Downloads\\\\APPL_test.csv\", 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile, lineterminator = '\\n') \n",
    "    csvwriter.writerows(test_data)\n",
    "with open(\"C:\\\\Users\\\\icode\\\\Downloads\\\\APPL_total.csv\", 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile, lineterminator = '\\n') \n",
    "    csvwriter.writerows(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same\n",
      "same\n",
      "same\n",
      "4\n",
      "same\n",
      "same\n",
      "same\n",
      "8\n",
      "same\n",
      "same\n",
      "same\n",
      "12\n",
      "same\n",
      "same\n",
      "same\n",
      "16\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "21\n",
      "same\n",
      "same\n",
      "same\n",
      "25\n",
      "same\n",
      "same\n",
      "same\n",
      "29\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "34\n",
      "same\n",
      "same\n",
      "same\n",
      "38\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "43\n",
      "same\n",
      "same\n",
      "same\n",
      "47\n",
      "same\n",
      "same\n",
      "same\n",
      "51\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "56\n",
      "same\n",
      "same\n",
      "same\n",
      "60\n",
      "same\n",
      "same\n",
      "same\n",
      "64\n",
      "same\n",
      "same\n",
      "same\n",
      "68\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "73\n",
      "same\n",
      "same\n",
      "same\n",
      "77\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "82\n",
      "same\n",
      "same\n",
      "same\n",
      "86\n",
      "same\n",
      "same\n",
      "same\n",
      "90\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "95\n",
      "same\n",
      "same\n",
      "same\n",
      "99\n",
      "same\n",
      "same\n",
      "same\n",
      "103\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "108\n",
      "same\n",
      "same\n",
      "same\n",
      "112\n",
      "same\n",
      "same\n",
      "same\n",
      "116\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "121\n",
      "same\n",
      "same\n",
      "same\n",
      "125\n",
      "same\n",
      "same\n",
      "same\n",
      "129\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "134\n",
      "same\n",
      "same\n",
      "same\n",
      "138\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "143\n",
      "same\n",
      "same\n",
      "same\n",
      "147\n",
      "same\n",
      "same\n",
      "same\n",
      "151\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "156\n",
      "same\n",
      "same\n",
      "same\n",
      "160\n",
      "same\n",
      "same\n",
      "same\n",
      "164\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "169\n",
      "same\n",
      "same\n",
      "same\n",
      "173\n",
      "same\n",
      "same\n",
      "same\n",
      "177\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "182\n",
      "same\n",
      "same\n",
      "same\n",
      "186\n",
      "same\n",
      "same\n",
      "same\n",
      "190\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "195\n",
      "same\n",
      "same\n",
      "same\n",
      "199\n",
      "same\n",
      "same\n",
      "same\n",
      "203\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "208\n",
      "same\n",
      "same\n",
      "same\n",
      "212\n",
      "same\n",
      "same\n",
      "same\n",
      "216\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "221\n",
      "same\n",
      "same\n",
      "same\n",
      "225\n",
      "same\n",
      "same\n",
      "same\n",
      "229\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "234\n",
      "same\n",
      "same\n",
      "same\n",
      "238\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "243\n",
      "same\n",
      "same\n",
      "same\n",
      "247\n",
      "same\n",
      "same\n",
      "same\n",
      "251\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "256\n",
      "same\n",
      "same\n",
      "same\n",
      "260\n",
      "same\n",
      "same\n",
      "same\n",
      "264\n",
      "same\n",
      "same\n",
      "same\n",
      "268\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "273\n",
      "same\n",
      "same\n",
      "same\n",
      "277\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "282\n",
      "same\n",
      "same\n",
      "same\n",
      "286\n",
      "same\n",
      "same\n",
      "same\n",
      "290\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "295\n",
      "same\n",
      "same\n",
      "same\n",
      "299\n",
      "same\n",
      "same\n",
      "same\n",
      "303\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "308\n",
      "same\n",
      "same\n",
      "same\n",
      "312\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "317\n",
      "same\n",
      "same\n",
      "same\n",
      "321\n",
      "same\n",
      "same\n",
      "same\n",
      "325\n",
      "same\n",
      "same\n",
      "same\n",
      "329\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "334\n",
      "same\n",
      "same\n",
      "same\n",
      "338\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "343\n",
      "same\n",
      "same\n",
      "same\n",
      "347\n",
      "same\n",
      "same\n",
      "same\n",
      "351\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "356\n",
      "same\n",
      "same\n",
      "same\n",
      "360\n",
      "same\n",
      "same\n",
      "same\n",
      "364\n",
      "same\n",
      "same\n",
      "same\n",
      "4\n",
      "same\n",
      "same\n",
      "same\n",
      "8\n",
      "same\n",
      "same\n",
      "same\n",
      "12\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "17\n",
      "same\n",
      "same\n",
      "same\n",
      "21\n",
      "same\n",
      "same\n",
      "same\n",
      "25\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "30\n",
      "same\n",
      "same\n",
      "same\n",
      "34\n",
      "same\n",
      "same\n",
      "same\n",
      "38\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n",
      "43\n",
      "same\n",
      "same\n",
      "same\n",
      "47\n",
      "same\n",
      "same\n",
      "same\n",
      "same\n"
     ]
    }
   ],
   "source": [
    "#splits samples based off of months\n",
    "\n",
    "train_samples_index = []\n",
    "for index in range(len(train_data)-2):\n",
    "    date_current = train_data[index+1][0]\n",
    "    date_next = train_data[index+2][0]\n",
    "    if date_current[:7] == date_next[:7]:\n",
    "        print(\"same\")\n",
    "    else:\n",
    "        train_samples_index.append(index+1)\n",
    "        print(index+1)\n",
    "\n",
    "test_samples_index = []\n",
    "for index in range(len(test_data)-2):\n",
    "    date_current = test_data[index+1][0]\n",
    "    date_next = test_data[index+2][0]\n",
    "    if date_current[:7] == date_next[:7]:\n",
    "        print(\"same\")\n",
    "    else:\n",
    "        test_samples_index.append(index+1)\n",
    "        print(index+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits samples based off grouping of 4weeks input, 1 week output\n",
    "\n",
    "train_samples_index = []\n",
    "for i in range(len(train_data) - 1):\n",
    "    if i % 5 == 0 and i != 0:\n",
    "        train_samples_index.append(i)\n",
    "\n",
    "test_samples_index = []\n",
    "for i in range(len(test_data) - 1):\n",
    "    if i % 5 == 0 and i != 0:\n",
    "        test_samples_index.append(i)\n",
    "\n",
    "total_samples_index = []\n",
    "for i in range(len(total_data) - 1):\n",
    "    if i % 5 == 0 and i != 0:\n",
    "        total_samples_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "start_index = 1\n",
    "end_index = 1\n",
    "for indexes in train_samples_index:\n",
    "    end_index = indexes + 1\n",
    "    train_samples.append(train_data[start_index:end_index])\n",
    "    start_index = end_index\n",
    "\n",
    "total_samples = []\n",
    "start_index = 1\n",
    "end_index = 1\n",
    "for indexes in total_samples_index:\n",
    "    end_index = indexes + 1\n",
    "    total_samples.append(total_data[start_index:end_index])\n",
    "    start_index = end_index\n",
    "\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
